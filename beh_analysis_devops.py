# -*- coding: utf-8 -*-
"""beh_analysis_devops.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g_-QbISIXXSY_M0QbSTpC7U3162zTn3O
"""

# Install dependencies
#!pip install scikit-learn pyyaml

# Import libraries
import yaml
import pickle
import sys

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

import statsmodels.api as sm

csv_path = sys.argv[1]

# Load the CSV file
df = pd.read_csv(csv_path)
print(df.head())

#df = pd.read_csv("/content/user_behavior_dataset.csv")

plt.style.use("ggplot")

df.head()

df.drop("User ID", axis=1, inplace=True)

df.head()

df.isnull().sum()

df.describe()

df.info()

df_cnt = pd.DataFrame(df["Device Model"].value_counts()).reset_index()

sns.barplot(df_cnt, x="Device Model", y="count")

df_cnt = pd.DataFrame(df["Operating System"].value_counts()).reset_index()

sns.barplot(df_cnt, x="Operating System", y="count")

df_cnt = pd.DataFrame(df["Gender"].value_counts()).reset_index()

sns.barplot(df_cnt, x="Gender", y="count")

df_cnt = pd.DataFrame(df["User Behavior Class"].value_counts()).reset_index()

sns.barplot(df_cnt, x="User Behavior Class", y="count")

sns.displot(df["Number of Apps Installed"])

df.head()

sns.pairplot(df[["App Usage Time (min/day)","Screen On Time (hours/day)","Battery Drain (mAh/day)","Data Usage (MB/day)","Age", "Number of Apps Installed","User Behavior Class"]], hue="User Behavior Class")

df_cnt_model = df.groupby("Device Model")["User Behavior Class"].value_counts().reset_index()

sns.barplot(df_cnt_model,x="Device Model", y = "count", hue="User Behavior Class")
plt.xticks(rotation=90)
plt.show()

df_cnt_os = df.groupby("Operating System")["User Behavior Class"].value_counts().reset_index()

sns.barplot(df_cnt_os,x="Operating System", y = "count", hue="User Behavior Class")
plt.xticks(rotation=90)
plt.show()

df_cnt_gender = df.groupby("Gender")["User Behavior Class"].value_counts().reset_index()

sns.barplot(df_cnt_gender,x="Gender", y = "count", hue="User Behavior Class")
plt.xticks(rotation=90)
plt.show()

columns_to_encode = ["Device Model", "Operating System", "Gender"]

df_encoded = pd.get_dummies(df[columns_to_encode], drop_first=True, dtype=int)

df_final = pd.concat([df,df_encoded], axis=1)
df_final.drop(columns_to_encode, axis=1, inplace=True)

df_final.head()

plt.figure(figsize=(12, 12))
sns.heatmap(df_final.corr(), cmap="RdYlGn", annot=True)
plt.show()

from sklearn.model_selection import  train_test_split
X = df_final.drop("User Behavior Class", axis=1)
Y = df_final["User Behavior Class"]
X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.3)

cols_to_scale = ["App Usage Time (min/day)","Screen On Time (hours/day)","Battery Drain (mAh/day)","Data Usage (MB/day)","Number of Apps Installed","Age"]

from sklearn.preprocessing import  StandardScaler
scaler = StandardScaler()

X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])

### Checking for multicollinearity
plt.figure(figsize=(12, 12))
sns.heatmap(X_train.corr(), cmap="RdYlGn", annot=True)
plt.show()

### Multi collinearity detected
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = [variance_inflation_factor(X_train.values, i)
for i in range(X_train.shape[1])]
df_vif = pd.DataFrame(zip(X_train.columns,vif), columns=["columns","vif"])

df_vif

X_train_lr = X_train.drop("Device Model_iPhone 12", axis=1)

vif = [variance_inflation_factor(X_train_lr.values, i)
for i in range(X_train_lr.shape[1])]
df_vif = pd.DataFrame(zip(X_train_lr.columns,vif), columns=["columns","vif"])

df_vif

X_train_lr = X_train_lr.drop("App Usage Time (min/day)", axis=1)

df_vif

X_train_lr = X_train_lr.drop("Screen On Time (hours/day)", axis=1)

vif = [variance_inflation_factor(X_train_lr.values, i)
for i in range(X_train_lr.shape[1])]
df_vif = pd.DataFrame(zip(X_train_lr.columns,vif), columns=["columns","vif"])

df_vif

X_train_lr = X_train_lr.drop("Battery Drain (mAh/day)", axis=1)

vif = [variance_inflation_factor(X_train_lr.values, i)
for i in range(X_train_lr.shape[1])]
df_vif = pd.DataFrame(zip(X_train_lr.columns,vif), columns=["columns","vif"])

df_vif

X_train_lr = X_train_lr.drop("Number of Apps Installed", axis=1)

vif = [variance_inflation_factor(X_train_lr.values, i)
for i in range(X_train_lr.shape[1])]
df_vif = pd.DataFrame(zip(X_train_lr.columns,vif), columns=["columns","vif"])

df_vif

from sklearn.model_selection import RandomizedSearchCV

from sklearn.decomposition import PCA

pca = PCA(random_state=42)

pca.fit(X_train, y_train)
df_pca = pd.DataFrame(zip(X_train.columns,pca.explained_variance_ratio_), columns=["columns", "variance"])

df_pca["cumsum"] = np.cumsum(df_pca["variance"])

df_pca.head()

sns.lineplot(data = df_pca, x=[i for i in range(len(df_pca))], y="cumsum")

### Using 5 features
pca_2 = PCA(n_components=5, random_state=42)

pca_2 = PCA(n_components=5, random_state=42)

X_train_pca = pca_2.fit_transform(X_train)

X_test_pca = pca_2.transform(X_test)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

param_grid = {    "max_depth":range(3, 10, 2),    "min_samples_split": range(10, 50, 5),    "min_samples_leaf": range(10, 50, 5),    "n_estimators": [10,30, 50, 80, 100, 120]}

cv = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_jobs=-1, cv=4, n_iter=20)

cv.fit(X_train_pca, y_train)

cv.best_score_

cv.best_params_

model_1 = cv.best_estimator_

pred = model_1.predict(X_test_pca)

from sklearn.metrics import confusion_matrix, classification_report

print(classification_report(pred, y_test))

# prompt: how to print confusion matrix

cm = confusion_matrix(pred,y_test)
cm

# prompt: print confusion matrix as heat map

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Save the model to a pickle file
with open('model.pkl', 'wb') as f:
    pickle.dump(model_1, f)

# Save the PCA and model configuration to a YAML file
config = {
    'pca': {
        'n_components': 5,
        'explained_variance_ratio': pca.explained_variance_ratio_.tolist(),
    },
    'model': {
        'best_params': cv.best_params_,
        'best_score': cv.best_score_,
        'n_estimators': model_1.n_estimators,
        'max_depth': model_1.max_depth,
        'min_samples_split': model_1.min_samples_split,
        'min_samples_leaf': model_1.min_samples_leaf,
    }
}

with open('config.yaml', 'w') as f:
    yaml.dump(config, f)

# Print confirmation
print("Model and configuration saved successfully!")

#!git clone https://github.com/hjose17/behaviour_analysis_devops.git

# Commented out IPython magic to ensure Python compatibility.
# %cd behaviour_analysis_devops/

#!mv /content/model.pkl /content/behaviour_analysis_devops/

#!mv /content/config.yaml /content/behaviour_analysis_devops/

#!git add .

#!git config --global user.email "hancyjose97@gmail.com"

#!git config --global user.name "hjose17"

#!git branch

#!git branch -M main

#!git push -u origin main

#!git init

#!git remote add origin https://github.com/hjose17/behaviour_analysis_devops.git

#!git add .

#!git commit -m "Initial commit"

#!git branch -M main
#!git push -u origin main

#!git remote set-url origin https://hjose17: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@github.com/hjose17/behaviour_analysis_devops.git

#!git push -u origin main

